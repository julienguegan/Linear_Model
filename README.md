# Linear_Model
Some practical work about the linear model to understand basics concepts of statistical estimation

## Ordinary Least Square

We have **n** observations **(y,x)**. We make the hypothesis of the linear model and we define the estimator that **minimize the sum of the squares errors**. 
The first orders conditions for this minimization allow to find easily the values of the parameters of the OLS estimator (**slope** and **intercept**). 
We can then compute values like the **coefficient of determination R2**, give **confidence intervals**, do predictions or make hypothesis test.

## Regularization : Ridge - Lasso

Penalization terms allows to simplify a problem when it is ill-conditionned and it can select main variables.


